{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT, READ_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/javm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/javm/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/javm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/javm/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Standard imports\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#SKlearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer, sent_tokenize\n",
    "from nltk import WordNetLemmatizer # lemmatizer using WordNet\n",
    "from nltk.corpus import wordnet # imports WordNet\n",
    "from nltk import pos_tag # nltk's native part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# # Create some tensors and perform an operation\n",
    "# a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "# b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "# c = tf.matmul(a, b)\n",
    "\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/javm/Desktop/Projects/Book-Recommendations/books_with_blurbs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Blurb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>Here, for the first time in paperback, is an o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>The fascinating, true story of the world's dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>Winnie and Helen have kept each others worst s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0425176428</td>\n",
       "      <td>What If?: The World's Foremost Military Histor...</td>\n",
       "      <td>Robert Cowley</td>\n",
       "      <td>2000</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "      <td>Historians and inquisitive laymen alike love t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1881320189</td>\n",
       "      <td>Goodbye to the Buttermilk Sky</td>\n",
       "      <td>Julia Oliver</td>\n",
       "      <td>1994</td>\n",
       "      <td>River City Pub</td>\n",
       "      <td>This highly praised first novel by fiction wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57505</th>\n",
       "      <td>0451458877</td>\n",
       "      <td>Tainted Trail</td>\n",
       "      <td>Wen Spencer</td>\n",
       "      <td>2002</td>\n",
       "      <td>Roc</td>\n",
       "      <td>Ukiah Oregon, half-man and half-alien raised b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57506</th>\n",
       "      <td>0399148736</td>\n",
       "      <td>Twelve Mile Limit</td>\n",
       "      <td>Randy Wayne White</td>\n",
       "      <td>2002</td>\n",
       "      <td>Penguin Putnam</td>\n",
       "      <td>On a Friday in early November, four people hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57507</th>\n",
       "      <td>0399148841</td>\n",
       "      <td>The Man With the Red Tattoo (James Bond 007)</td>\n",
       "      <td>Raymond Benson</td>\n",
       "      <td>2002</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "      <td>On a quiet late-night flight from Tokyo to Lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57508</th>\n",
       "      <td>0553578979</td>\n",
       "      <td>Iron Fist (Star Wars: X-Wing Series, Book 6)</td>\n",
       "      <td>Aaron Allston</td>\n",
       "      <td>1998</td>\n",
       "      <td>Bantam</td>\n",
       "      <td>They are the Rebel Alliance's ultimate strike ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57509</th>\n",
       "      <td>0345391101</td>\n",
       "      <td>The Adventures of Lando Calrissian: Lando Calr...</td>\n",
       "      <td>L. Neil Smith</td>\n",
       "      <td>1994</td>\n",
       "      <td>Del Rey Books</td>\n",
       "      <td>For the price of one, you get three Lando Calr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57510 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ISBN                                              Title  \\\n",
       "0      0060973129                               Decision in Normandy   \n",
       "1      0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "2      0399135782                             The Kitchen God's Wife   \n",
       "3      0425176428  What If?: The World's Foremost Military Histor...   \n",
       "4      1881320189                      Goodbye to the Buttermilk Sky   \n",
       "...           ...                                                ...   \n",
       "57505  0451458877                                      Tainted Trail   \n",
       "57506  0399148736                                  Twelve Mile Limit   \n",
       "57507  0399148841       The Man With the Red Tattoo (James Bond 007)   \n",
       "57508  0553578979       Iron Fist (Star Wars: X-Wing Series, Book 6)   \n",
       "57509  0345391101  The Adventures of Lando Calrissian: Lando Calr...   \n",
       "\n",
       "                  Author  Year                 Publisher  \\\n",
       "0           Carlo D'Este  1991           HarperPerennial   \n",
       "1       Gina Bari Kolata  1999      Farrar Straus Giroux   \n",
       "2                Amy Tan  1991          Putnam Pub Group   \n",
       "3          Robert Cowley  2000  Berkley Publishing Group   \n",
       "4           Julia Oliver  1994            River City Pub   \n",
       "...                  ...   ...                       ...   \n",
       "57505        Wen Spencer  2002                       Roc   \n",
       "57506  Randy Wayne White  2002            Penguin Putnam   \n",
       "57507     Raymond Benson  2002   Putnam Publishing Group   \n",
       "57508      Aaron Allston  1998                    Bantam   \n",
       "57509      L. Neil Smith  1994             Del Rey Books   \n",
       "\n",
       "                                                   Blurb  \n",
       "0      Here, for the first time in paperback, is an o...  \n",
       "1      The fascinating, true story of the world's dea...  \n",
       "2      Winnie and Helen have kept each others worst s...  \n",
       "3      Historians and inquisitive laymen alike love t...  \n",
       "4      This highly praised first novel by fiction wri...  \n",
       "...                                                  ...  \n",
       "57505  Ukiah Oregon, half-man and half-alien raised b...  \n",
       "57506  On a Friday in early November, four people hea...  \n",
       "57507  On a quiet late-night flight from Tokyo to Lon...  \n",
       "57508  They are the Rebel Alliance's ultimate strike ...  \n",
       "57509  For the price of one, you get three Lando Calr...  \n",
       "\n",
       "[57510 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT COMPILATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Whole_Text']= df['Title'] + \" \" + df ['Author'] + \" \" + df['Publisher'] + \" \" + df['Blurb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.drop(columns = ['ISBN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Blurb</th>\n",
       "      <th>Whole_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>Here, for the first time in paperback, is an o...</td>\n",
       "      <td>Decision in Normandy Carlo D'Este HarperPerenn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>The fascinating, true story of the world's dea...</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>Winnie and Helen have kept each others worst s...</td>\n",
       "      <td>The Kitchen God's Wife Amy Tan Putnam Pub Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What If?: The World's Foremost Military Histor...</td>\n",
       "      <td>Robert Cowley</td>\n",
       "      <td>2000</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "      <td>Historians and inquisitive laymen alike love t...</td>\n",
       "      <td>What If?: The World's Foremost Military Histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goodbye to the Buttermilk Sky</td>\n",
       "      <td>Julia Oliver</td>\n",
       "      <td>1994</td>\n",
       "      <td>River City Pub</td>\n",
       "      <td>This highly praised first novel by fiction wri...</td>\n",
       "      <td>Goodbye to the Buttermilk Sky Julia Oliver Riv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57505</th>\n",
       "      <td>Tainted Trail</td>\n",
       "      <td>Wen Spencer</td>\n",
       "      <td>2002</td>\n",
       "      <td>Roc</td>\n",
       "      <td>Ukiah Oregon, half-man and half-alien raised b...</td>\n",
       "      <td>Tainted Trail Wen Spencer Roc Ukiah Oregon, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57506</th>\n",
       "      <td>Twelve Mile Limit</td>\n",
       "      <td>Randy Wayne White</td>\n",
       "      <td>2002</td>\n",
       "      <td>Penguin Putnam</td>\n",
       "      <td>On a Friday in early November, four people hea...</td>\n",
       "      <td>Twelve Mile Limit Randy Wayne White Penguin Pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57507</th>\n",
       "      <td>The Man With the Red Tattoo (James Bond 007)</td>\n",
       "      <td>Raymond Benson</td>\n",
       "      <td>2002</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "      <td>On a quiet late-night flight from Tokyo to Lon...</td>\n",
       "      <td>The Man With the Red Tattoo (James Bond 007) R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57508</th>\n",
       "      <td>Iron Fist (Star Wars: X-Wing Series, Book 6)</td>\n",
       "      <td>Aaron Allston</td>\n",
       "      <td>1998</td>\n",
       "      <td>Bantam</td>\n",
       "      <td>They are the Rebel Alliance's ultimate strike ...</td>\n",
       "      <td>Iron Fist (Star Wars: X-Wing Series, Book 6) A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57509</th>\n",
       "      <td>The Adventures of Lando Calrissian: Lando Calr...</td>\n",
       "      <td>L. Neil Smith</td>\n",
       "      <td>1994</td>\n",
       "      <td>Del Rey Books</td>\n",
       "      <td>For the price of one, you get three Lando Calr...</td>\n",
       "      <td>The Adventures of Lando Calrissian: Lando Calr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57510 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title             Author  \\\n",
       "0                                   Decision in Normandy       Carlo D'Este   \n",
       "1      Flu: The Story of the Great Influenza Pandemic...   Gina Bari Kolata   \n",
       "2                                 The Kitchen God's Wife            Amy Tan   \n",
       "3      What If?: The World's Foremost Military Histor...      Robert Cowley   \n",
       "4                          Goodbye to the Buttermilk Sky       Julia Oliver   \n",
       "...                                                  ...                ...   \n",
       "57505                                      Tainted Trail        Wen Spencer   \n",
       "57506                                  Twelve Mile Limit  Randy Wayne White   \n",
       "57507       The Man With the Red Tattoo (James Bond 007)     Raymond Benson   \n",
       "57508       Iron Fist (Star Wars: X-Wing Series, Book 6)      Aaron Allston   \n",
       "57509  The Adventures of Lando Calrissian: Lando Calr...      L. Neil Smith   \n",
       "\n",
       "       Year                 Publisher  \\\n",
       "0      1991           HarperPerennial   \n",
       "1      1999      Farrar Straus Giroux   \n",
       "2      1991          Putnam Pub Group   \n",
       "3      2000  Berkley Publishing Group   \n",
       "4      1994            River City Pub   \n",
       "...     ...                       ...   \n",
       "57505  2002                       Roc   \n",
       "57506  2002            Penguin Putnam   \n",
       "57507  2002   Putnam Publishing Group   \n",
       "57508  1998                    Bantam   \n",
       "57509  1994             Del Rey Books   \n",
       "\n",
       "                                                   Blurb  \\\n",
       "0      Here, for the first time in paperback, is an o...   \n",
       "1      The fascinating, true story of the world's dea...   \n",
       "2      Winnie and Helen have kept each others worst s...   \n",
       "3      Historians and inquisitive laymen alike love t...   \n",
       "4      This highly praised first novel by fiction wri...   \n",
       "...                                                  ...   \n",
       "57505  Ukiah Oregon, half-man and half-alien raised b...   \n",
       "57506  On a Friday in early November, four people hea...   \n",
       "57507  On a quiet late-night flight from Tokyo to Lon...   \n",
       "57508  They are the Rebel Alliance's ultimate strike ...   \n",
       "57509  For the price of one, you get three Lando Calr...   \n",
       "\n",
       "                                              Whole_Text  \n",
       "0      Decision in Normandy Carlo D'Este HarperPerenn...  \n",
       "1      Flu: The Story of the Great Influenza Pandemic...  \n",
       "2      The Kitchen God's Wife Amy Tan Putnam Pub Grou...  \n",
       "3      What If?: The World's Foremost Military Histor...  \n",
       "4      Goodbye to the Buttermilk Sky Julia Oliver Riv...  \n",
       "...                                                  ...  \n",
       "57505  Tainted Trail Wen Spencer Roc Ukiah Oregon, ha...  \n",
       "57506  Twelve Mile Limit Randy Wayne White Penguin Pu...  \n",
       "57507  The Man With the Red Tattoo (James Bond 007) R...  \n",
       "57508  Iron Fist (Star Wars: X-Wing Series, Book 6) A...  \n",
       "57509  The Adventures of Lando Calrissian: Lando Calr...  \n",
       "\n",
       "[57510 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57510 entries, 0 to 57509\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Title       57510 non-null  object\n",
      " 1   Author      57510 non-null  object\n",
      " 2   Year        57510 non-null  int64 \n",
      " 3   Publisher   57510 non-null  object\n",
      " 4   Blurb       57510 non-null  object\n",
      " 5   Whole_Text  57510 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        pass\n",
    "    \n",
    "    def fit(self, data, y = 0):\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, data, y = 0):\n",
    "        fully_normalized_corpus = data.apply(self.process_doc)\n",
    "        \n",
    "        return fully_normalized_corpus\n",
    "        \n",
    "    def process_doc(self, doc):\n",
    "\n",
    "        wnl = WordNetLemmatizer()\n",
    "        stop_words = stopwords.words('english')\n",
    "        \n",
    "        def pos_tagger(nltk_tag):\n",
    "            if nltk_tag.startswith('J'):\n",
    "                return wordnet.ADJ\n",
    "            elif nltk_tag.startswith('V'):\n",
    "                return wordnet.VERB\n",
    "            elif nltk_tag.startswith('N'):\n",
    "                return wordnet.NOUN\n",
    "            elif nltk_tag.startswith('R'):\n",
    "                return wordnet.ADV\n",
    "            else:         \n",
    "                return None\n",
    "\n",
    "        doc_norm = [tok.lower() for tok in word_tokenize(doc) if (tok.isalpha())]\n",
    "\n",
    "        wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tag(doc_norm))) \n",
    "        doc_norm = [wnl.lemmatize(token, pos) for token, pos in wordnet_tagged if pos is not None]\n",
    "\n",
    "        return \" \".join(doc_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['norm_text'] = tp.fit_transform(train_df['Whole_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns = ['Whole_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train_df['norm_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(corpus):\n",
    "#     cleaned_text = []\n",
    "#     cleaned_text2 = []\n",
    "#     corpus = re.sub(\"'\", \"\", corpus)\n",
    "#     corpus = re.sub(\"(\\\\d|\\\\W)+\",\" \",corpus)\n",
    "#     corpus = re.sub(\"/[^A-Z0-9]+/ig\", \"\",corpus)\n",
    "#     corpus = corpus.replace('_','')\n",
    "#     cleaned_text = [wn.lemmatize(word, pos = 'v') for word in word_tokenize(corpus.lower()) if black_txt(word)]\n",
    "#     cleaned_text2 = [word for word in cleaned_text if black_txt(word)]\n",
    "#     return \" \".join(cleaned_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 3, max_df = 10, max_features = 5000)\n",
    "vectors = vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df = pd.DataFrame(vectors.toarray(),\n",
    "                     columns=[k for k, v in sorted(vectorizer.vocabulary_.items(), \n",
    "                     key=lambda item: item[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aahz</th>\n",
       "      <th>abandona</th>\n",
       "      <th>abba</th>\n",
       "      <th>abingdon</th>\n",
       "      <th>abnormally</th>\n",
       "      <th>abort</th>\n",
       "      <th>abrahams</th>\n",
       "      <th>abram</th>\n",
       "      <th>absalom</th>\n",
       "      <th>absolution</th>\n",
       "      <th>...</th>\n",
       "      <th>την</th>\n",
       "      <th>της</th>\n",
       "      <th>τον</th>\n",
       "      <th>του</th>\n",
       "      <th>жизни</th>\n",
       "      <th>на</th>\n",
       "      <th>не</th>\n",
       "      <th>به</th>\n",
       "      <th>في</th>\n",
       "      <th>من</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57505</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57506</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57507</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57508</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57509</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57510 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aahz  abandona  abba  abingdon  abnormally  abort  abrahams  abram  \\\n",
       "0       0.0       0.0   0.0       0.0         0.0    0.0       0.0    0.0   \n",
       "1       0.0       0.0   0.0       0.0         0.0    0.0       0.0    0.0   \n",
       "2       0.0       0.0   0.0       0.0         0.0    0.0       0.0    0.0   \n",
       "3       0.0       0.0   0.0       0.0         0.0    0.0       0.0    0.0   \n",
       "4       0.0       0.0   0.0       0.0         0.0    0.0       0.0    0.0   \n",
       "...     ...       ...   ...       ...         ...    ...       ...    ...   \n",
       "57505   0.0       0.0   0.0       0.0         0.0    0.0       0.0    0.0   \n",
       "57506   0.0       0.0   0.0       0.0         0.0    0.0       0.0    0.0   \n",
       "57507   0.0       0.0   0.0       0.0         0.0    0.0       0.0    0.0   \n",
       "57508   0.0       0.0   0.0       0.0         0.0    0.0       0.0    0.0   \n",
       "57509   0.0       0.0   0.0       0.0         0.0    0.0       0.0    0.0   \n",
       "\n",
       "       absalom  absolution  ...  την  της  τον  του  жизни   на   не   به  \\\n",
       "0          0.0         0.0  ...  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   \n",
       "1          0.0         0.0  ...  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   \n",
       "2          0.0         0.0  ...  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   \n",
       "3          0.0         0.0  ...  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   \n",
       "4          0.0         0.0  ...  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   \n",
       "...        ...         ...  ...  ...  ...  ...  ...    ...  ...  ...  ...   \n",
       "57505      0.0         0.0  ...  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   \n",
       "57506      0.0         0.0  ...  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   \n",
       "57507      0.0         0.0  ...  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   \n",
       "57508      0.0         0.0  ...  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   \n",
       "57509      0.0         0.0  ...  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   \n",
       "\n",
       "        في   من  \n",
       "0      0.0  0.0  \n",
       "1      0.0  0.0  \n",
       "2      0.0  0.0  \n",
       "3      0.0  0.0  \n",
       "4      0.0  0.0  \n",
       "...    ...  ...  \n",
       "57505  0.0  0.0  \n",
       "57506  0.0  0.0  \n",
       "57507  0.0  0.0  \n",
       "57508  0.0  0.0  \n",
       "57509  0.0  0.0  \n",
       "\n",
       "[57510 rows x 5000 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_search = input('What are you looking for: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to read a book about dragons and thier history\n"
     ]
    }
   ],
   "source": [
    "print(book_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = tp.fit_transform(pd.Series(book_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i want read book dragon thier history\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_vec = vectorizer.transform(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cosine_similarity(search_vec, vectors)\n",
    "#vec_df.apply(lambda x: cosine_similarity(x,search_vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : Decision in Normandy\n",
      "Author : Carlo D'Este\n",
      "Publisher : HarperPerennial\n",
      "Blurb : Here, for the first time in paperback, is an outstanding military history that offers a dramatic new perspective on the Allied campaign that began with the invasion of the D-Day beaches of Normandy. Nationa advertising in Military History.\n"
     ]
    }
   ],
   "source": [
    "best_book = np.argmax(test[0])\n",
    "\n",
    "print('Title : {}'.format(train_df.loc[best_book, 'Title']))\n",
    "print('Author : {}'.format(train_df.loc[best_book, 'Author']))\n",
    "print('Publisher : {}'.format(train_df.loc[best_book, 'Publisher']))\n",
    "print('Blurb : {}'.format(train_df.loc[best_book, 'Blurb']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('tf-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a519badb918331f0d8c64ed18a42c37ad23f1f7898e2293b12d9d4e1cd8409d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
